{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W200 Python Fundamentals for Data Science, UC Berkeley MIDS\n",
    "# Final Exam\n",
    "\n",
    "\n",
    "## Instructions\n",
    "The final exam is designed to evaluate your grasp of Python theory as well as Python coding.\n",
    "\n",
    "- This is an individual exam.\n",
    "- You have 24 hours to complete the exam, starting from the point at which you first access it.\n",
    "- You will be graded on the quality of your answers.  Use clear, persuasive arguments based on concepts we covered in class.\n",
    "- While we've left one code/markdown cell for you after each question as a placeholder, some of your answers will require multiple cells to fully respond\n",
    "- Double click the markdown cells where it says YOUR ANSWER HERE to enter your written answers; if you need more cells for your written answers, please make them markdown cells (rather than code cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOUR NAME HERE\n",
    "Grace Yuqing Lin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: General Questions (21 pts )\n",
    "\n",
    "a) The following method is part of a larger program used by a mobile phone company.  It will work when an object of type MobileDevice or of type ServiceContract is passed in.  This is a demonstration of (select all that apply and state a reason why it applies):\n",
    "\n",
    "    1. Inheritance\n",
    "    2. Polymorphism\n",
    "    3. Duck typing\n",
    "    4. Top-down design\n",
    "    5. Functional programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method:\n",
    "\n",
    "def add_to_cart(item):\n",
    "    cart.append(item)\n",
    "    total += item.price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a) Your answer here\n",
    "\n",
    "This specific code is a demonstration of Duck Typing. As it work both on type MobileDevice and type ServiceContract. The object's suitability is determined by the presence of certain methods and properties, rather than the type of the object itself. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Suppose you have a long list of digits (0-9) that you want to write to a file.  Would it be more efficient to use ASCII or UTF-8 as an encoding?  How could you create an even smaller binary file to store the information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- b) Your answer here\n",
    "\n",
    "It would be equivalently efficient to use ASCII and UTF-8 because they use the exact same bytes for a list of digits. However, ASCII is preferred if we want to create a smaller binary file as it can be compressed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) You are part of a team working on a spreadsheet program that is written in Python 3.  The program includes several classes to represent different types of objects that fit into a cell of a spreadsheet.  Give a strong argument for why your team should write an abstract base class to represent such objects and give examples of what should go into such an abstract base class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- c) Your answer here\n",
    "\n",
    "We need abstract base class because it offers an intermediate solution between the free-form of Python and a staticly-typed language. In a teamwork setting, abstract base class can make sure every one is on the same page implementing those subclasses. It can define shared API for a set of subclasses. In addition, if we don't implement all necessary methods (and properties), we will get an error upon instantiation, rather than an AttributeError, potentially much later. Some examples could be insert() and delete() functions with common properties like color and fonts. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Explain why NumPy is better than lists for \"vectorized\" math operations. Give an example of an operation that is either impossible or painful to implement using traditional Python lists compared to NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- d) Your answer here\n",
    "\n",
    "Lists cannot be carried out by efficient C loops, each iteration would require type checks and other Python API bookkeeping. Numpy allows fast parallel computation at several levels: Vector or array operations, which allow to execute similar operations simultaneously on a bunch of data. Through the following example, we can see numpy is much faster than list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.3 ms ± 3.53 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# if we multiply two sequences with a list comprehension: \n",
    "import random\n",
    "a = [random.randint(1, 100) for i in range(100000)]\n",
    "b = [random.randint(1, 100) for j in range(100000)]\n",
    "%timeit result = [x * y for x, y in zip(a, b)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159 µs ± 15.5 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# it's much faster and easiler to understand if we use numpy:\n",
    "import numpy as np\n",
    "a = np.random.randint(1, 100, 100000)\n",
    "b = np.random.randint(1, 100, 100000)\n",
    "%timeit result = a * b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) We want a list of the numbers that are the square of nonnegative integer less than 10, but whose squares are greater than 10.  The list comprehension below gives an empty list.  Correct it so that we get the desired output: [16, 25, 36, 49, 64, 81]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x**2 for x in range(10) if x**2 > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Explain why the following code prints what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'function'>\n"
     ]
    }
   ],
   "source": [
    "def f(): pass\n",
    "print(type(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- f) Your answer here\n",
    "\n",
    "f is a function we just defined with no specific instructions. The print(type(f)) just shows the type of f, which is a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Explain why the following code prints something different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "def f(): pass\n",
    "print(type(f()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- g) Your answer here\n",
    "\n",
    "The print(type(f())) just shows the type of the result of f, which is an empty value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Data Integrity (25 pts)\n",
    "\n",
    "a) Why is it important to sanity-check your data before you begin your analysis? What could happen if you don't?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a) Your answer here\n",
    "\n",
    "If the data has some unreasonable values, it could impact our result. For example, if we are calculating average age, and some records has negative ages, it would negatively impact the average age we calculate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Explain, in your own words, why real-world data is often messy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- b) Your answer here\n",
    "\n",
    "Because the data types could be very different. For example, if we want to use datetime, there are so many different formats for such information. We need to normalize such features first to be able to run analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) How do you determine which variables in your dataset you should check for issues prior to starting an analysis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- c) Your answer here\n",
    "\n",
    "We can use describe function to check the data and have a summarized view. If we see any extrem values, we should check further. In addition, if we know the data based on common sense, we can investigate even more. For example, if we are testing colors, and use set function to find unique color values, find \"unbrella\", this could also be an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) How do you know when you have adequately checked these variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- d) Your answer here\n",
    "\n",
    "We can draw graphs to see if those variables look reasonable. We can write specific test codes to run tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Is it possible to fully vet your data for errors before you begin your analysis? If not, what should you be looking out for while you complete your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- e) Your answer here\n",
    "\n",
    "It's not possible to fully vet the data before begin the analysis under most circustances. There could be some type errors or miscellaneous errors showing up during the anlaysis. We should look for data consistency and look out for extreme values/missing values/type errors, etc while we complete the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3:  Elections (24 pts)\n",
    "\n",
    "Consider the following data frame in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>delegates</th>\n",
       "      <th>color</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marco</td>\n",
       "      <td>165</td>\n",
       "      <td>blue</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jeb</td>\n",
       "      <td>0</td>\n",
       "      <td>red</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chris</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>donald</td>\n",
       "      <td>1543</td>\n",
       "      <td>white</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ted</td>\n",
       "      <td>559</td>\n",
       "      <td>blue</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>john</td>\n",
       "      <td>161</td>\n",
       "      <td>red</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  delegates  color state\n",
       "0   marco        165   blue    FL\n",
       "1     jeb          0    red    FL\n",
       "2   chris          0  white    NJ\n",
       "3  donald       1543  white    NY\n",
       "4     ted        559   blue    TX\n",
       "5    john        161    red    OH"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "# creating a data frame from scratch - list of lists\n",
    "\n",
    "data = [ ['marco', 165, 'blue', 'FL'], \n",
    "         ['jeb', 0, 'red', 'FL'], \n",
    "         ['chris', 0, 'white', 'NJ'], \n",
    "         ['donald', 1543, 'white', 'NY'],\n",
    "         ['ted', 559, 'blue', 'TX'],\n",
    "         ['john', 161, 'red', 'OH']\n",
    "       ]\n",
    "\n",
    "# create a data frame with column names - list of lists\n",
    "\n",
    "col_names = ['name', 'delegates', 'color', 'state']\n",
    "df = pandas.DataFrame(data, columns=col_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Using bracket indexing in Pandas, show how many delegates `ted` got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Your answer here\n",
    "df.index = df.name\n",
    "df.loc['ted'].delegates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Using bracket indexing in Pandas, show how many total delegates were obtained by candidates whose favorite color is blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "724"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b) Your answer here\n",
    "df.index = df.color\n",
    "df.loc['blue'].delegates.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Using groupby and aggregate in Pandas, show how many total delegates were obtained by candidates grouped by favorite color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       delegates\n",
      "color           \n",
      "blue         724\n",
      "red          161\n",
      "white       1543\n"
     ]
    }
   ],
   "source": [
    "# c) Your answer here\n",
    "print(df.groupby('color').agg({'delegates': 'sum'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Clinical disease data (30 pts)\n",
    "\n",
    "Your boss comes to you Monday morning and says “I figured out our next step; we are going to pivot from an online craft store and become a data center for genetic disease information! I found **ClinVar** which is a repository that contains expert curated data, and it is free for the taking. This is a gold mine! Take a week and tell me what gene and mutation combinations are classified as dangerous.”\n",
    "\n",
    "1)  Look at the sample data set (in the Sample ClinVar data below or in the .txt file) and develop a plan of action to use python to extract and summarize just what your boss wants. **Don’t code**. You can use pseudocode and/or and essay format to generate a plan in 500 words or less. \n",
    "\n",
    "2) Tell us the output that you expect from your planned code\n",
    "\n",
    "**Hints:**  \n",
    "\n",
    "* Look at the sample file carefully. What fields do you want to extract? Are they in the same place every time? What strategy will you use to robustly extract and filter your data of interest? How do you plan to handle missing data?\n",
    "\n",
    "* Filter out junk. Just focus on what your boss asked for (1) gene name (2) mutation reference. (3) Filter your data to include only mutations that are dangerous as you define it. \n",
    "\n",
    "* Pandas and NumPy parsers correctly recognize the end of each line in in the ClinVar file.\n",
    "\n",
    "* The unit of observation of this dataset is one row per mutation.\n",
    "\n",
    "* While you shouldn't code your analysis, creating a few lines of code while you think through the problem may be helpful (so that you can sanity check that your plan works). So you can experiment, we have included the data file below as a Tab Separated Value file \"Genomics_Questions.txt\". Please do not submit any such code. For example, if I wanted to check that I accurately understand the \"split\" function in the context of this data, I could type:\n",
    "\n",
    "```python\n",
    "sample = \"abc;def;asd\"\n",
    "test = sample.split(';')\n",
    "```\n",
    "\n",
    "**This is a planning question we want you to lay out a plan in text not code.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VCF file description (Summarized from version 4.1)\n",
    "\n",
    "\n",
    "* The VCF specification:\n",
    "\n",
    "VCF is a text file format which contains meta-information lines, a header\n",
    "line, and then data lines each containing information about a position in the genome. The format also has the ability to contain genotype information on samples for each position.\n",
    "\n",
    "* Fixed fields:\n",
    "\n",
    "There are 8 fixed fields per record. All data lines are **tab-delimited**. In all cases, missing values are specified with a dot (‘.’). \n",
    "\n",
    "1. CHROM - chromosome number\n",
    "2. POS - position DNA nuceleotide count (bases) along the chromosome\n",
    "3. ID - The unique identifier for each mutation\n",
    "4. REF - reference base(s) alleles\n",
    "5. ALT - alternate base(s) alleles\n",
    "6. QUAL - Phred scaled quality score\n",
    "7. FILTER - filter status (if position has passed all filters)\n",
    "8. INFO - a semicolon-separated series of  keys with values in the format: <key>=<data>, and specified as <key>=<data name>[data value definition].\n",
    "\n",
    "\n",
    "### INFO field specifications\n",
    "\n",
    "```\n",
    "GENEINFO = <Gene symbol>\n",
    "CLNSIG =  <Variant Clinical Significance (Severity)\n",
    "  0 – unknown\t(Uncertain significance)\n",
    "  1 – untested\t(not provided)\n",
    "  2 - non-pathogenic\t(Benign)\n",
    "  3 - probable-non-pathogenic\t(Likely benign)\n",
    "  4 - probable-pathogenic\t(Likely pathogenic)\n",
    "  5 – pathogenic\t(Pathogenic)\n",
    "  6 - drug-response\t(drug response)\n",
    "  7 – histocompatibility\t(histocompatibility)\n",
    "  255 - other\t(other)\n",
    "```\n",
    "\n",
    "### Representative/Sample ClinVar data (vcf file format)\n",
    "\n",
    "```\n",
    "##fileformat=VCFv4.0\t\t\t\t\t\t\t\n",
    "##fileDate=20160705\t\t\t\t\t\t\t\n",
    "##source=ClinVar and dbSNP\t\t\t\t\t\t\t\n",
    "##dbSNP_BUILD_ID=147\t\t\t\t\t\t\t\n",
    "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\n",
    "1\t949523\trs786201005\tC\tT\t.\t.\tGENEINFO=ISG15;CLNSIG=5\n",
    "1\t949696\trs672601345\tC\tCG\t.\t.\tGENEINFO=ISG15;CLNSIG=5;CLNDBN=Cancer\n",
    "1\t949739\trs672601312\tG\tT\t.\t.\tGENEINFO=ISG15;CLNDBN=Cancer\n",
    "1\t955597\trs115173026\tG\tT\t.\t.\tGENEINFO=AGRN;CLNSIG=2; CLNDBN=Cancer\n",
    "1\t955619\trs201073369\tG\tC\t.\t.\tGENEINFO=AGG;CLNDBN=Heart_dis \n",
    "1\t957640\trs6657048\tC\tT\t.\t.\tGENEINFO=AGG;CLNSIG=3;CLNDBN=Heart_dis \n",
    "1\t976059\trs544749044\tC\tT\t.\t.\tGENEINFO=AGG;CLNSIG=0;CLNDBN=Heart_dis \n",
    "```\n",
    "\n",
    "A second version of this file is provided as a .txt file in case you want to load it into your console to test it out. You can use either file for the data modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Your answer here (use as many cells as you need!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are only focused on genes and mutations, I would like to extract ID and INFO. I will build my own filter based on data quality to obtain the experimental data set. \n",
    "\n",
    "I will convert and normalize the fields. For example, I will summarize the describe the numeric data to see if there is any extreme values, such as negative number in CLNSIG. \n",
    "\n",
    "I will seperate the info file into different columns based on semicolon. In this case, because some observations have CLNDBN  and some do not, making the data sometimes not in the same place. We need to map those data into correct column names. \n",
    "\n",
    "In terms of missing data, if it is in the fields of importance, we can exclude these observations. If they are in the fields we already exclude, we can still use those observations.\n",
    "\n",
    "I will extract observations with clnsig between 4 and 7. I define those observations as \"dangerous\". \n",
    "\n",
    "Furthermore, I can start by slicing the dataset into 30% test and 70% train data. Build a model on the train data then test it on the test data. Exploring the relationship among mutation number, geneinfo, and clinsig. Using clinsig as an indictor, importing numpy, seaborn, etc libraries, to plot the correlation and heat map. Try different models (logistic regression, random forest) to fit the train data. \n",
    "\n",
    "I expect the output to be a clean dataset with mutation ID, gene name, and CLNSIG. In addition, there could be an input box for people to type in gene name, mutation ID, and the program could tell the possibility getting a disease. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
